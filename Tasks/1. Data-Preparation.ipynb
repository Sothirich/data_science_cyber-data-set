{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danet\n",
    "\n",
    "## Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danet\n",
    "\n",
    "### reading data\n",
    "df1=pd.read_csv('Data/Data_of_Attack_Back.csv')\n",
    "df2=pd.read_csv('Data/Data_of_Attack_Back_BufferOverflow.csv')\n",
    "df3=pd.read_csv('Data/Data_of_Attack_Back_FTPWrite.csv')\n",
    "df4=pd.read_csv('Data/Data_of_Attack_Back_GuessPassword.csv')\n",
    "df5=pd.read_csv('Data/Data_of_Attack_Back_NMap.csv')\n",
    "df6=pd.read_csv('Data/Data_of_Attack_Back_Neptune.csv')\n",
    "df7=pd.read_csv('Data/Data_of_Attack_Back_Normal.csv')\n",
    "df8=pd.read_csv('Data/Data_of_Attack_Back_PortSweep.csv')\n",
    "df9=pd.read_csv('Data/Data_of_Attack_Back_RootKit.csv')\n",
    "df10=pd.read_csv('Data/Data_of_Attack_Back_Satan.csv')\n",
    "df11=pd.read_csv('Data/Data_of_Attack_Back_Smurf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danet\n",
    "\n",
    "### add missing header to Data_of_Attack_Back_FTPWrite.csv\n",
    "header = df1.columns\n",
    "df3.columns = header\n",
    "\n",
    "### add new column attack\n",
    "df1['attack']=['data_of_attack_back']*df1.shape[0]\n",
    "df2['attack']=['data_of_attack_back_BufferOverflow']*df2.shape[0]\n",
    "df3['attack']=['data_of_attack_back_FTPWrite']*df3.shape[0]\n",
    "df4['attack']=['data_of_attack_back_GuessPassword']*df4.shape[0]\n",
    "df5['attack']=['data_of_attack_back_NMap']*df5.shape[0]\n",
    "df6['attack']=['data_of_attack_back_Neptune']*df6.shape[0]\n",
    "df7['attack']=['data_of_attack_back_Normal']*df7.shape[0]\n",
    "df8['attack']=['data_of_attack_back_PortSweep']*df8.shape[0]\n",
    "df9['attack']=['data_of_attack_back_RootKit']*df9.shape[0]\n",
    "df10['attack']=['data_of_attack_back_Satan']*df10.shape[0]\n",
    "df11['attack']=['data_of_attack_back_Smurf']*df11.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danet\n",
    "\n",
    "### concate all the data to one file\n",
    "df=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11])\n",
    "df.reset_index()\n",
    "\n",
    "### export data to csv file\n",
    "df.to_csv('Data/Data_of_Attack_Appends.csv', index=False)\n",
    "\n",
    "### export to a variable\n",
    "df = pd.read_csv('Data/Data_of_Attack_Appends.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danet\n",
    "\n",
    "### clean Unnamed columns\n",
    "df.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danet\n",
    "\n",
    "### check for null value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danet\n",
    "\n",
    "### dropping rows with missing values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danet\n",
    "\n",
    "### check duplicated row\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danet\n",
    "\n",
    "### drop duplicated row \n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danet\n",
    "\n",
    "### check data types\n",
    "# df.dtypes\n",
    "# df.columns\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danet\n",
    "\n",
    "### remove space in header\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "\n",
    "### exporting cleaned data to csv file\n",
    "df.to_csv('Data/Data_of_Attack_Appends_Clean.csv', index=False)\n",
    "\n",
    "### exporting cleaned data to a variable\n",
    "df = pd.read_csv('Data/Data_of_Attack_Appends_Clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danet\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitou\n",
    "\n",
    "## Importing libraries\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitou\n",
    "\n",
    "### Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "df['protocol_type'] = le.fit_transform(df['protocol_type'])\n",
    "df['service'] = le.fit_transform(df['service'])\n",
    "df['flag'] = le.fit_transform(df['flag'])\n",
    "\n",
    "### Display the encoded categorical variables\n",
    "# df['protocol_type']\n",
    "# df['service']\n",
    "# df['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitou\n",
    "\n",
    "### Normalize numerical variables\n",
    "scaler = MinMaxScaler()\n",
    "num_cols = ['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count', 'same_srv_rate', 'diff_srv_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_serror_rate']\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitou\n",
    "\n",
    "### Feature engineering\n",
    "# Create a new feature that measures the ratio of source bytes to destination bytes\n",
    "df['src_dst_ratio'] = df['src_bytes'] / (df['dst_bytes'] + 0.001)\n",
    "df['src_dst_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitou\n",
    "\n",
    "### Feature selection\n",
    "# Use SelectKBest with ANOVA F-value to select the 10 best features\n",
    "selector = SelectKBest(f_classif, k=10)\n",
    "selector.fit(df.drop('attack', axis=1), df['attack'])\n",
    "selected_cols = df.drop('attack', axis=1).columns[selector.get_support()]\n",
    "print('The selected features are:', selected_cols)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
